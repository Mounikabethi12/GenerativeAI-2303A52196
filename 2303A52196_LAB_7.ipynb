{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH0lPUqtGHVmy2oDJTr+Hb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mounikabethi12/GenerativeAI-2303A52196/blob/main/2303A52196_LAB_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NIwpk9j7UyTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNcsFsBBVHzw",
        "outputId": "8a80244a-3463-4ee1-f012-555cee481eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden Layer 1\n",
        "    Dense(16, activation='relu'),                                    # Hidden Layer 2\n",
        "    Dense(20, activation='relu'),                                    # Hidden Layer 3\n",
        "    Dense(10, activation='relu'),                                    # Hidden Layer 4\n",
        "    Dense(1, activation='sigmoid')                                   # Output Layer (binary classification)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRxRtdX6VmOW",
        "outputId": "376af969-0201-4eea-edc4-aa7c5d7edd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=150, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT8kZyX2YJ_R",
        "outputId": "712531b5-7a6c-4876-c6a9-a1acde84b1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6483 - loss: 2.7036 - val_accuracy: 0.6098 - val_loss: 2.9019\n",
            "Epoch 2/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6663 - loss: 2.7197 - val_accuracy: 0.6098 - val_loss: 2.8941\n",
            "Epoch 3/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6528 - loss: 2.7081 - val_accuracy: 0.6098 - val_loss: 2.8863\n",
            "Epoch 4/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6692 - loss: 2.6069 - val_accuracy: 0.6098 - val_loss: 2.8783\n",
            "Epoch 5/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6882 - loss: 2.4087 - val_accuracy: 0.6098 - val_loss: 2.8703\n",
            "Epoch 6/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6474 - loss: 2.6986 - val_accuracy: 0.6098 - val_loss: 2.8624\n",
            "Epoch 7/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6642 - loss: 2.6524 - val_accuracy: 0.6098 - val_loss: 2.8542\n",
            "Epoch 8/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6586 - loss: 2.6105 - val_accuracy: 0.6098 - val_loss: 2.8462\n",
            "Epoch 9/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6354 - loss: 2.7074 - val_accuracy: 0.6098 - val_loss: 2.8382\n",
            "Epoch 10/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6796 - loss: 2.6463 - val_accuracy: 0.6098 - val_loss: 2.8301\n",
            "Epoch 11/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6553 - loss: 2.5790 - val_accuracy: 0.6098 - val_loss: 2.8218\n",
            "Epoch 12/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6534 - loss: 2.7411 - val_accuracy: 0.6098 - val_loss: 2.8136\n",
            "Epoch 13/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6628 - loss: 2.6818 - val_accuracy: 0.6098 - val_loss: 2.8053\n",
            "Epoch 14/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6356 - loss: 2.7380 - val_accuracy: 0.6098 - val_loss: 2.7971\n",
            "Epoch 15/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6680 - loss: 2.4071 - val_accuracy: 0.6098 - val_loss: 2.7887\n",
            "Epoch 16/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6571 - loss: 2.6210 - val_accuracy: 0.6098 - val_loss: 2.7803\n",
            "Epoch 17/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6854 - loss: 2.3039 - val_accuracy: 0.6098 - val_loss: 2.7719\n",
            "Epoch 18/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6693 - loss: 2.4185 - val_accuracy: 0.6098 - val_loss: 2.7634\n",
            "Epoch 19/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6717 - loss: 2.5157 - val_accuracy: 0.6098 - val_loss: 2.7549\n",
            "Epoch 20/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6486 - loss: 2.6116 - val_accuracy: 0.6098 - val_loss: 2.7463\n",
            "Epoch 21/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6620 - loss: 2.6791 - val_accuracy: 0.6098 - val_loss: 2.7378\n",
            "Epoch 22/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6400 - loss: 2.6259 - val_accuracy: 0.6098 - val_loss: 2.7293\n",
            "Epoch 23/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6693 - loss: 2.4683 - val_accuracy: 0.6098 - val_loss: 2.7206\n",
            "Epoch 24/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6401 - loss: 2.5501 - val_accuracy: 0.6098 - val_loss: 2.7120\n",
            "Epoch 25/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6580 - loss: 2.5307 - val_accuracy: 0.6098 - val_loss: 2.7033\n",
            "Epoch 26/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6786 - loss: 2.2846 - val_accuracy: 0.6098 - val_loss: 2.6945\n",
            "Epoch 27/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6650 - loss: 2.4310 - val_accuracy: 0.6098 - val_loss: 2.6857\n",
            "Epoch 28/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6773 - loss: 2.4199 - val_accuracy: 0.6098 - val_loss: 2.6768\n",
            "Epoch 29/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6416 - loss: 2.6131 - val_accuracy: 0.6098 - val_loss: 2.6681\n",
            "Epoch 30/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6683 - loss: 2.4882 - val_accuracy: 0.6098 - val_loss: 2.6594\n",
            "Epoch 31/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6703 - loss: 2.4100 - val_accuracy: 0.6098 - val_loss: 2.6505\n",
            "Epoch 32/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6709 - loss: 2.3403 - val_accuracy: 0.6098 - val_loss: 2.6415\n",
            "Epoch 33/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6432 - loss: 2.6079 - val_accuracy: 0.6098 - val_loss: 2.6327\n",
            "Epoch 34/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6873 - loss: 2.1864 - val_accuracy: 0.6098 - val_loss: 2.6236\n",
            "Epoch 35/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6843 - loss: 2.2420 - val_accuracy: 0.6098 - val_loss: 2.6146\n",
            "Epoch 36/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6699 - loss: 2.3482 - val_accuracy: 0.6098 - val_loss: 2.6055\n",
            "Epoch 37/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6963 - loss: 2.0405 - val_accuracy: 0.6098 - val_loss: 2.5963\n",
            "Epoch 38/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6563 - loss: 2.6130 - val_accuracy: 0.6098 - val_loss: 2.5871\n",
            "Epoch 39/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6769 - loss: 2.3337 - val_accuracy: 0.6098 - val_loss: 2.5779\n",
            "Epoch 40/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6805 - loss: 2.1636 - val_accuracy: 0.6098 - val_loss: 2.5686\n",
            "Epoch 41/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6893 - loss: 2.2007 - val_accuracy: 0.6098 - val_loss: 2.5593\n",
            "Epoch 42/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6582 - loss: 2.3991 - val_accuracy: 0.6098 - val_loss: 2.5501\n",
            "Epoch 43/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6593 - loss: 2.3410 - val_accuracy: 0.6098 - val_loss: 2.5408\n",
            "Epoch 44/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6725 - loss: 2.2527 - val_accuracy: 0.6098 - val_loss: 2.5314\n",
            "Epoch 45/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6484 - loss: 2.2892 - val_accuracy: 0.6098 - val_loss: 2.5221\n",
            "Epoch 46/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6764 - loss: 2.1767 - val_accuracy: 0.6098 - val_loss: 2.5127\n",
            "Epoch 47/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6554 - loss: 2.3879 - val_accuracy: 0.6098 - val_loss: 2.5034\n",
            "Epoch 48/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6640 - loss: 2.3777 - val_accuracy: 0.6098 - val_loss: 2.4938\n",
            "Epoch 49/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6830 - loss: 2.1498 - val_accuracy: 0.6098 - val_loss: 2.4842\n",
            "Epoch 50/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6596 - loss: 2.2144 - val_accuracy: 0.6098 - val_loss: 2.4745\n",
            "Epoch 51/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6623 - loss: 2.4031 - val_accuracy: 0.6098 - val_loss: 2.4650\n",
            "Epoch 52/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6672 - loss: 2.1900 - val_accuracy: 0.6098 - val_loss: 2.4554\n",
            "Epoch 53/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6266 - loss: 2.5330 - val_accuracy: 0.6098 - val_loss: 2.4457\n",
            "Epoch 54/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6589 - loss: 2.4110 - val_accuracy: 0.6098 - val_loss: 2.4360\n",
            "Epoch 55/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6737 - loss: 2.1028 - val_accuracy: 0.6098 - val_loss: 2.4262\n",
            "Epoch 56/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6549 - loss: 2.3292 - val_accuracy: 0.6098 - val_loss: 2.4165\n",
            "Epoch 57/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6520 - loss: 2.3317 - val_accuracy: 0.6098 - val_loss: 2.4067\n",
            "Epoch 58/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6562 - loss: 2.2724 - val_accuracy: 0.6098 - val_loss: 2.3968\n",
            "Epoch 59/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6608 - loss: 2.2109 - val_accuracy: 0.6098 - val_loss: 2.3871\n",
            "Epoch 60/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6722 - loss: 2.1671 - val_accuracy: 0.6098 - val_loss: 2.3771\n",
            "Epoch 61/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6825 - loss: 1.9869 - val_accuracy: 0.6098 - val_loss: 2.3672\n",
            "Epoch 62/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6500 - loss: 2.2902 - val_accuracy: 0.6098 - val_loss: 2.3574\n",
            "Epoch 63/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6675 - loss: 2.1360 - val_accuracy: 0.6098 - val_loss: 2.3475\n",
            "Epoch 64/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6420 - loss: 2.1982 - val_accuracy: 0.6098 - val_loss: 2.3378\n",
            "Epoch 65/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6615 - loss: 2.0453 - val_accuracy: 0.6098 - val_loss: 2.3280\n",
            "Epoch 66/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6642 - loss: 2.0262 - val_accuracy: 0.6098 - val_loss: 2.3182\n",
            "Epoch 67/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6772 - loss: 2.0120 - val_accuracy: 0.6098 - val_loss: 2.3083\n",
            "Epoch 68/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6508 - loss: 2.0471 - val_accuracy: 0.6098 - val_loss: 2.2984\n",
            "Epoch 69/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6705 - loss: 1.9861 - val_accuracy: 0.6098 - val_loss: 2.2884\n",
            "Epoch 70/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6690 - loss: 2.3130 - val_accuracy: 0.6098 - val_loss: 2.2787\n",
            "Epoch 71/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6626 - loss: 2.1554 - val_accuracy: 0.6098 - val_loss: 2.2690\n",
            "Epoch 72/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6641 - loss: 2.0969 - val_accuracy: 0.6098 - val_loss: 2.2592\n",
            "Epoch 73/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6276 - loss: 2.3003 - val_accuracy: 0.6098 - val_loss: 2.2494\n",
            "Epoch 74/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6424 - loss: 2.1968 - val_accuracy: 0.6098 - val_loss: 2.2394\n",
            "Epoch 75/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6850 - loss: 2.0373 - val_accuracy: 0.6098 - val_loss: 2.2294\n",
            "Epoch 76/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6712 - loss: 1.9559 - val_accuracy: 0.6098 - val_loss: 2.2194\n",
            "Epoch 77/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6570 - loss: 2.1788 - val_accuracy: 0.6098 - val_loss: 2.2095\n",
            "Epoch 78/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6610 - loss: 1.9989 - val_accuracy: 0.6098 - val_loss: 2.1996\n",
            "Epoch 79/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6703 - loss: 1.9168 - val_accuracy: 0.6098 - val_loss: 2.1896\n",
            "Epoch 80/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6990 - loss: 1.7919 - val_accuracy: 0.6098 - val_loss: 2.1796\n",
            "Epoch 81/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6707 - loss: 1.8813 - val_accuracy: 0.6098 - val_loss: 2.1694\n",
            "Epoch 82/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6550 - loss: 1.9908 - val_accuracy: 0.6098 - val_loss: 2.1594\n",
            "Epoch 83/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6816 - loss: 1.9117 - val_accuracy: 0.6098 - val_loss: 2.1492\n",
            "Epoch 84/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6684 - loss: 1.7734 - val_accuracy: 0.6098 - val_loss: 2.1391\n",
            "Epoch 85/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6701 - loss: 1.9922 - val_accuracy: 0.6098 - val_loss: 2.1290\n",
            "Epoch 86/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6289 - loss: 2.1057 - val_accuracy: 0.6098 - val_loss: 2.1192\n",
            "Epoch 87/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6637 - loss: 1.8813 - val_accuracy: 0.6098 - val_loss: 2.1092\n",
            "Epoch 88/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6702 - loss: 1.8403 - val_accuracy: 0.6098 - val_loss: 2.0991\n",
            "Epoch 89/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6646 - loss: 2.0485 - val_accuracy: 0.6098 - val_loss: 2.0890\n",
            "Epoch 90/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6967 - loss: 1.8618 - val_accuracy: 0.6098 - val_loss: 2.0790\n",
            "Epoch 91/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6790 - loss: 1.8609 - val_accuracy: 0.6098 - val_loss: 2.0689\n",
            "Epoch 92/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6568 - loss: 1.8699 - val_accuracy: 0.6098 - val_loss: 2.0587\n",
            "Epoch 93/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6436 - loss: 1.9226 - val_accuracy: 0.6098 - val_loss: 2.0488\n",
            "Epoch 94/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6538 - loss: 1.8662 - val_accuracy: 0.6098 - val_loss: 2.0386\n",
            "Epoch 95/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6602 - loss: 1.8714 - val_accuracy: 0.6098 - val_loss: 2.0287\n",
            "Epoch 96/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6655 - loss: 1.8433 - val_accuracy: 0.6098 - val_loss: 2.0186\n",
            "Epoch 97/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6881 - loss: 1.8406 - val_accuracy: 0.6098 - val_loss: 2.0084\n",
            "Epoch 98/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6434 - loss: 1.9989 - val_accuracy: 0.6098 - val_loss: 1.9985\n",
            "Epoch 99/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6741 - loss: 1.8112 - val_accuracy: 0.6098 - val_loss: 1.9886\n",
            "Epoch 100/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6769 - loss: 1.6590 - val_accuracy: 0.6098 - val_loss: 1.9788\n",
            "Epoch 101/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6805 - loss: 1.6976 - val_accuracy: 0.6098 - val_loss: 1.9687\n",
            "Epoch 102/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6616 - loss: 1.7883 - val_accuracy: 0.6098 - val_loss: 1.9587\n",
            "Epoch 103/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6576 - loss: 1.8100 - val_accuracy: 0.6098 - val_loss: 1.9486\n",
            "Epoch 104/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6643 - loss: 1.7963 - val_accuracy: 0.6098 - val_loss: 1.9385\n",
            "Epoch 105/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6880 - loss: 1.6568 - val_accuracy: 0.6098 - val_loss: 1.9283\n",
            "Epoch 106/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6180 - loss: 1.9310 - val_accuracy: 0.6098 - val_loss: 1.9184\n",
            "Epoch 107/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6706 - loss: 1.7920 - val_accuracy: 0.6098 - val_loss: 1.9084\n",
            "Epoch 108/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6775 - loss: 1.6758 - val_accuracy: 0.6098 - val_loss: 1.8984\n",
            "Epoch 109/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6828 - loss: 1.7177 - val_accuracy: 0.6098 - val_loss: 1.8883\n",
            "Epoch 110/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6612 - loss: 1.7799 - val_accuracy: 0.6098 - val_loss: 1.8783\n",
            "Epoch 111/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6403 - loss: 1.7163 - val_accuracy: 0.6098 - val_loss: 1.8684\n",
            "Epoch 112/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6814 - loss: 1.6194 - val_accuracy: 0.6098 - val_loss: 1.8585\n",
            "Epoch 113/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6804 - loss: 1.6949 - val_accuracy: 0.6098 - val_loss: 1.8487\n",
            "Epoch 114/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6623 - loss: 1.8168 - val_accuracy: 0.6098 - val_loss: 1.8388\n",
            "Epoch 115/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6992 - loss: 1.4718 - val_accuracy: 0.6098 - val_loss: 1.8289\n",
            "Epoch 116/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6721 - loss: 1.7008 - val_accuracy: 0.6098 - val_loss: 1.8191\n",
            "Epoch 117/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6648 - loss: 1.7220 - val_accuracy: 0.6098 - val_loss: 1.8094\n",
            "Epoch 118/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6581 - loss: 1.6587 - val_accuracy: 0.6098 - val_loss: 1.7994\n",
            "Epoch 119/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6633 - loss: 1.6900 - val_accuracy: 0.6098 - val_loss: 1.7897\n",
            "Epoch 120/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6933 - loss: 1.4680 - val_accuracy: 0.6098 - val_loss: 1.7799\n",
            "Epoch 121/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6541 - loss: 1.8174 - val_accuracy: 0.6098 - val_loss: 1.7704\n",
            "Epoch 122/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6691 - loss: 1.6173 - val_accuracy: 0.6098 - val_loss: 1.7607\n",
            "Epoch 123/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6862 - loss: 1.5375 - val_accuracy: 0.6098 - val_loss: 1.7509\n",
            "Epoch 124/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6666 - loss: 1.4735 - val_accuracy: 0.6098 - val_loss: 1.7412\n",
            "Epoch 125/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6838 - loss: 1.4503 - val_accuracy: 0.6098 - val_loss: 1.7316\n",
            "Epoch 126/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6575 - loss: 1.6332 - val_accuracy: 0.6098 - val_loss: 1.7221\n",
            "Epoch 127/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6633 - loss: 1.5892 - val_accuracy: 0.6098 - val_loss: 1.7127\n",
            "Epoch 128/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6494 - loss: 1.6757 - val_accuracy: 0.6098 - val_loss: 1.7032\n",
            "Epoch 129/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6593 - loss: 1.6955 - val_accuracy: 0.6098 - val_loss: 1.6938\n",
            "Epoch 130/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6615 - loss: 1.5073 - val_accuracy: 0.6098 - val_loss: 1.6843\n",
            "Epoch 131/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6829 - loss: 1.4502 - val_accuracy: 0.6098 - val_loss: 1.6749\n",
            "Epoch 132/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6694 - loss: 1.6046 - val_accuracy: 0.6098 - val_loss: 1.6655\n",
            "Epoch 133/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6714 - loss: 1.6333 - val_accuracy: 0.6098 - val_loss: 1.6563\n",
            "Epoch 134/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6778 - loss: 1.5094 - val_accuracy: 0.6098 - val_loss: 1.6468\n",
            "Epoch 135/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6767 - loss: 1.4957 - val_accuracy: 0.6098 - val_loss: 1.6377\n",
            "Epoch 136/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6748 - loss: 1.3990 - val_accuracy: 0.6098 - val_loss: 1.6284\n",
            "Epoch 137/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6616 - loss: 1.5284 - val_accuracy: 0.6098 - val_loss: 1.6190\n",
            "Epoch 138/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6701 - loss: 1.4443 - val_accuracy: 0.6098 - val_loss: 1.6098\n",
            "Epoch 139/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6779 - loss: 1.3726 - val_accuracy: 0.6098 - val_loss: 1.6006\n",
            "Epoch 140/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6477 - loss: 1.5472 - val_accuracy: 0.6098 - val_loss: 1.5914\n",
            "Epoch 141/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6689 - loss: 1.3444 - val_accuracy: 0.6098 - val_loss: 1.5822\n",
            "Epoch 142/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6843 - loss: 1.2772 - val_accuracy: 0.6098 - val_loss: 1.5731\n",
            "Epoch 143/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6679 - loss: 1.3946 - val_accuracy: 0.6098 - val_loss: 1.5641\n",
            "Epoch 144/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6779 - loss: 1.4503 - val_accuracy: 0.6098 - val_loss: 1.5553\n",
            "Epoch 145/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6370 - loss: 1.6019 - val_accuracy: 0.6098 - val_loss: 1.5467\n",
            "Epoch 146/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6674 - loss: 1.3334 - val_accuracy: 0.6098 - val_loss: 1.5380\n",
            "Epoch 147/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6654 - loss: 1.5069 - val_accuracy: 0.6098 - val_loss: 1.5293\n",
            "Epoch 148/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6661 - loss: 1.3247 - val_accuracy: 0.6098 - val_loss: 1.5208\n",
            "Epoch 149/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6457 - loss: 1.5168 - val_accuracy: 0.6098 - val_loss: 1.5123\n",
            "Epoch 150/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6775 - loss: 1.4076 - val_accuracy: 0.6098 - val_loss: 1.5037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "biRuTqbLYUbR",
        "outputId": "d2d6dbb7-d5ea-4e12-8e53-fa27d22451b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c1e53076660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Test Accuracy: 0.64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.00\n",
            "Recall: 0.00\n",
            "F1 Score: 0.00\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      1.00      0.78        99\n",
            "           1       0.00      0.00      0.00        55\n",
            "\n",
            "    accuracy                           0.64       154\n",
            "   macro avg       0.32      0.50      0.39       154\n",
            "weighted avg       0.41      0.64      0.50       154\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/diabetes_ann_model.h5')\n",
        "\n",
        "\n",
        "loaded_model = keras.models.load_model('/content/diabetes_ann_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1WwG2P3anH5",
        "outputId": "4801abd5-8346-42ed-e137-9dbc021d1397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = np.array([X_test[0]])\n",
        "\n",
        "prediction = (loaded_model.predict(sample_data) > 0.5).astype(int)\n",
        "print(f'Prediction for sample data: {prediction[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5iRpywGattW",
        "outputId": "736e11b4-51ea-42a0-f7b0-a16aa9f02e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "Prediction for sample data: 0\n"
          ]
        }
      ]
    }
  ]
}